
// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview Transforms a child's drawing into a realistic image, with selectable styles.
 *
 * - transformDrawing - A function that handles the drawing transformation process.
 * - TransformDrawingInput - The input type for the transformDrawing function.
 * - TransformDrawingOutput - The return type for the transformDrawing function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const TransformDrawingInputSchema = z.object({
  drawingDataUri: z
    .string()
    .describe(
      "A drawing of a child, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
  styleDescription: z
    .string()
    .optional()
    .nullable()
    .describe('An optional description of the artistic style to apply, e.g., "cartoon", "storybook illustration". If null or empty, a default artistic interpretation will be used.'),
  modelName: z.string().optional().describe('The Genkit model name to use for image generation, e.g., googleai/gemini-2.0-flash-exp.'),
  userRefinementPrompt: z
    .string()
    .optional()
    .nullable()
    .describe('An optional short text prompt from the user to refine the generation, e.g., "This is a cat".'),
});
export type TransformDrawingInput = z.infer<typeof TransformDrawingInputSchema>;

const TransformDrawingOutputSchema = z.object({
  realisticImageDataUri: z
    .string()
    .describe("The transformed image as a data URI."),
});
export type TransformDrawingOutput = z.infer<typeof TransformDrawingOutputSchema>;

export async function transformDrawing(input: TransformDrawingInput): Promise<TransformDrawingOutput> {
  return transformDrawingFlow(input);
}

const transformDrawingFlow = ai.defineFlow(
  {
    name: 'transformDrawingFlow',
    inputSchema: TransformDrawingInputSchema,
    outputSchema: TransformDrawingOutputSchema,
  },
  async input => {
    const { drawingDataUri, styleDescription, modelName, userRefinementPrompt } = input;
    const chosenModel = modelName || 'googleai/gemini-2.0-flash-exp'; // Default to gemini-2.0-flash-exp
    console.log(`[transformDrawingFlow] Attempting image generation with model: ${chosenModel}, Style: ${styleDescription || 'Default Artistic'}, Refinement: ${userRefinementPrompt || 'None'}`);

    let systemInstruction = `You are an AI artist specializing in bringing children's drawings to life. Your task is to transform the provided child's drawing into an image.
Your primary goal is to interpret the subject directly from the child's drawing and then bring those *exact drawn shapes* to life, preserving their unique character.
The artistic style chosen should be applied *to the doodle's forms*, not by reinterpreting the subject into a generic version of that style.`;

    if (styleDescription && styleDescription.trim() !== "") {
      systemInstruction += `\n\nPlease render the drawing in the following artistic style: ${styleDescription}. Remember to apply this style directly to the drawn shapes and the interpreted subject from the doodle.`;
    } else {
      // Default interpretation if no style is provided or if it's an empty string
      systemInstruction += `\n\nPlease transform this drawing into an imaginative and visually striking artistic interpretation of what is drawn, be creative, but ensure the core shapes from the drawing are clearly recognizable!`;
    }

    const structuralRequirements = `
Key requirements for structural fidelity (these ALWAYS apply, regardless of style):
1.  **Preserve Original Form:** The generated image MUST strictly follow the outlines and major shapes of the original drawing. Treat the drawn lines as the definitive boundaries for the subject(s). Do not redraw or reinterpret the subject into a standard realistic form; instead, apply the chosen style *to the exact shapes and forms present in the doodle*. If a child draws a wobbly square, the output should be a wobbly square rendered in the chosen style, not a perfect square.
2.  **Contained Realism/Styling:** When applying textures or a specific style (e.g., 'photorealistic', 'cartoon', 'claymation'), these stylistic elements (like fur, scales, metal, cartoon outlines, clay texture) should be 'squashed into' and contained *within* the original drawn shapes. The overall silhouette and form must remain true to the doodle. For example, if a doodle depicts specific abstract shapes, realistic textures should be applied *to those abstract shapes*, not by transforming them into a generic object that deviates from the drawn form.
3.  **Maintain Character and Subject Interpretation:** Your primary source for interpreting the subject matter (e.g., if it's an animal, object, or abstract design) should be the visual cues in the doodle itself. Avoid defaulting to common subjects like cats unless the doodle or a user hint strongly suggests it. If a user provides a hint (e.g., "This is a friendly robot"), that hint should be heavily prioritized in your interpretation of the subject. Keep the spirit, pose, and any discernible features of the original figures. If a figure looks like a specific thing based on the doodle or hint, enhance that depiction while staying true to its drawn form.
4.  **Lighting and Background:** Use soft, natural lighting unless the style dictates otherwise (e.g., dramatic lighting for a superhero cartoon). The background should be simple and unobtrusive, perhaps a very light color wash or a subtle, out-of-focus texture that doesn't distract from the main subject(s), unless the style demands a specific background (e.g., a space background for an astronaut drawing).
5.  **Expression and Mood:** If figures have expressions, maintain or enhance them in a friendly, playful, and non-scary way, suitable for children, consistent with the chosen style.
6.  **Composition:** The final image should feel like a photograph or artwork of the child's imagined creation brought to life. Do not add significant new elements not clearly suggested by the original drawing. If multiple, distinct figures are present, transform each one according to these guidelines, maintaining their spatial relationship. The overall aspect ratio (landscape or portrait) of the generated image should closely match the aspect ratio of the original drawing provided.

Transform the following drawing:`;

    let fullPromptText = `${systemInstruction}\n\n${structuralRequirements}`;

    // Construct the prompt parts for ai.generate
    const promptParts: any[] = [
      { media: { url: drawingDataUri } },
      { text: fullPromptText }
    ];

    if (userRefinementPrompt && userRefinementPrompt.trim() !== "") {
      promptParts.push({
        text: `\n\nIMPORTANT USER HINT: The user has specified that this drawing is: "${userRefinementPrompt}". Please use this information as the primary guide for the subject matter, while still applying the overall requested style and structural rules outlined above.`
      });
    }


    try {
      console.log('[transformDrawingFlow] Input URI (first 100 chars):', drawingDataUri.substring(0, 100) + '...');
      console.log('[transformDrawingFlow] Full prompt parts for AI:', JSON.stringify(promptParts.map(p => p.text ? {text: p.text} : {media: 'present'}), null, 2));


      const generationResult = await ai.generate({
        model: chosenModel,
        prompt: promptParts,
        config: {
          responseModalities: ['TEXT', 'IMAGE'],
        },
      });

      console.log('[transformDrawingFlow] Genkit ai.generate() result:', JSON.stringify(generationResult, null, 2));

      const media = generationResult.media;

      if (!media || !media.url) {
        console.error('[transformDrawingFlow] Image generation failed: media or media.url is missing in the AI response.', generationResult);
        const aiErrorDetails = generationResult.text || 'No specific error message from AI.';
        throw new Error(`AI image generation failed to produce a valid media URL. AI reason: ${aiErrorDetails}`);
      }

      console.log('[transformDrawingFlow] Image generated successfully, media.url (first 100 chars):', media.url.substring(0, 100) + '...');
      return {realisticImageDataUri: media.url};

    } catch (error: any) {
      console.error('[transformDrawingFlow] Error within transformDrawingFlow:', error.message, error.stack, error.cause ? JSON.stringify(error.cause) : '', 'Input model was:', chosenModel);
      throw error; // Re-throw the error to be caught by the calling function
    }
  }
);

